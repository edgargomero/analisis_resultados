#!/usr/bin/env python3
"""
CEAPSI - Aplicaci√≥n Principal del Sistema PCF
Sistema completo de predicci√≥n y an√°lisis de llamadas para call center
"""

import streamlit as st
import sys
import os
import warnings

# Suprimir warnings menores
warnings.filterwarnings('ignore', category=UserWarning, module='pandas')
import logging
from datetime import datetime

# Configurar logging detallado
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ceapsi_app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('CEAPSI_APP')
from pathlib import Path

# Agregar el directorio actual al path para imports
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# Importar m√≥dulos del sistema
from dashboard_comparacion import DashboardValidacionCEAPSI
import subprocess
import json
from datetime import datetime
import io
import tempfile
import pandas as pd
import os

# Configuraci√≥n de la p√°gina principal
st.set_page_config(
    page_title="CEAPSI - Sistema PCF",
    page_icon="üìû",
    layout="wide",
    initial_sidebar_state="expanded"
)

def mostrar_seccion_carga_archivos():
    """Secci√≥n para cargar archivos de datos manualmente"""
    
    st.sidebar.markdown("### üìÅ Cargar Datos")
    
    # Mostrar estado actual
    if st.session_state.datos_cargados:
        st.sidebar.success("‚úÖ Datos cargados correctamente")
        
        # Bot√≥n para limpiar datos
        if st.sidebar.button("üóëÔ∏è Limpiar Datos", use_container_width=True):
            st.session_state.archivo_datos = None
            st.session_state.datos_cargados = False
            st.rerun()
    else:
        st.sidebar.warning("‚ö†Ô∏è No hay datos cargados")
    
    # Uploader de archivos
    archivo_subido = st.sidebar.file_uploader(
        "Seleccionar archivo de llamadas:",
        type=['csv', 'xlsx', 'xls'],
        help="Formatos soportados: CSV, Excel (.xlsx, .xls)"
    )
    
    if archivo_subido is not None:
        if st.sidebar.button("üöÄ Procesar Archivo", use_container_width=True, type="primary"):
            procesar_archivo_subido(archivo_subido)
    
    # Informaci√≥n sobre el formato esperado
    with st.sidebar.expander("üìù Formato de Datos Esperado"):
        st.markdown("""
        **Columnas requeridas:**
        - `FECHA`: Fecha y hora de la llamada
        - `TELEFONO`: N√∫mero de tel√©fono
        - `SENTIDO`: 'in' (entrante) o 'out' (saliente)
        - `ATENDIDA`: 'Si' o 'No'
        
        **Formato de fecha esperado:**
        - DD-MM-YYYY HH:MM:SS
        - Ejemplo: 02-01-2023 08:08:07
        
        **Separador CSV:** Punto y coma (;)
        
        **Archivo de ejemplo:**
        Descarga un archivo de ejemplo para probar el sistema.
        """)
        
        # Bot√≥n para descargar ejemplo
        try:
            with open(os.path.join(os.path.dirname(__file__), 'ejemplo_datos_llamadas.csv'), 'r', encoding='utf-8') as f:
                ejemplo_csv = f.read()
            
            st.download_button(
                "üìé Descargar Ejemplo CSV",
                data=ejemplo_csv,
                file_name="ejemplo_datos_llamadas.csv",
                mime="text/csv",
                help="Archivo de ejemplo con el formato correcto"
            )
        except:
            pass
    
    st.sidebar.markdown("---")

def procesar_archivo_subido(archivo_subido):
    """Procesa el archivo subido y lo guarda temporalmente"""
    
    logger.info(f"Iniciando procesamiento de archivo: {archivo_subido.name}")
    
    try:
        with st.spinner("Procesando archivo..."):
            logger.info(f"Archivo tipo: {archivo_subido.type if hasattr(archivo_subido, 'type') else 'desconocido'}")
            logger.info(f"Tama√±o archivo: {archivo_subido.size if hasattr(archivo_subido, 'size') else 'desconocido'} bytes")
            
            # Leer el archivo seg√∫n su tipo
            if archivo_subido.name.endswith('.csv'):
                logger.info("Procesando archivo CSV")
                # Intentar diferentes encodings para CSV
                contenido_bytes = archivo_subido.read()
                logger.info(f"Bytes le√≠dos: {len(contenido_bytes)}")
                
                for encoding in ['utf-8', 'latin-1', 'cp1252']:
                    try:
                        logger.info(f"Intentando encoding: {encoding}")
                        contenido_str = contenido_bytes.decode(encoding)
                        df = pd.read_csv(io.StringIO(contenido_str), sep=';')
                        logger.info(f"CSV le√≠do exitosamente con encoding {encoding}")
                        break
                    except UnicodeDecodeError as e:
                        logger.warning(f"Fallo encoding {encoding}: {e}")
                        continue
                else:
                    logger.error("No se pudo decodificar el archivo CSV con ning√∫n encoding")
                    st.error("‚ùå No se pudo decodificar el archivo CSV")
                    return
            
            elif archivo_subido.name.endswith(('.xlsx', '.xls')):
                logger.info("Procesando archivo Excel")
                df = pd.read_excel(archivo_subido)
                logger.info("Excel le√≠do exitosamente")
            
            logger.info(f"DataFrame cargado: {len(df)} filas, {len(df.columns)} columnas")
            logger.info(f"Columnas encontradas: {list(df.columns)}")
            
            # Validar columnas requeridas
            columnas_requeridas = ['FECHA', 'TELEFONO']
            columnas_faltantes = [col for col in columnas_requeridas if col not in df.columns]
            
            logger.info(f"Validando columnas requeridas: {columnas_requeridas}")
            
            if columnas_faltantes:
                logger.error(f"Columnas faltantes: {columnas_faltantes}")
                st.error(f"‚ùå Columnas faltantes: {', '.join(columnas_faltantes)}")
                st.info("üìù Columnas encontradas: " + ", ".join(df.columns.tolist()))
                return
            
            # Validar que hay datos
            if len(df) == 0:
                logger.error("El archivo est√° vac√≠o")
                st.error("‚ùå El archivo est√° vac√≠o")
                return
            
            logger.info("Validaci√≥n exitosa, guardando archivo temporal")
            
            # Guardar en sesi√≥n temporal
            archivo_temp = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8')
            logger.info(f"Archivo temporal creado: {archivo_temp.name}")
            
            df.to_csv(archivo_temp.name, sep=';', index=False, encoding='utf-8')
            archivo_temp.close()
            
            # Actualizar estado
            st.session_state.archivo_datos = archivo_temp.name
            st.session_state.datos_cargados = True
            
            logger.info(f"Datos guardados exitosamente. Estado actualizado.")
            
            st.success(f"‚úÖ Archivo procesado exitosamente: {len(df):,} registros cargados")
            
            # Mostrar celebraci√≥n
            st.balloons()
            
            # Mostrar resumen de datos
            st.info(f"üìä **Resumen del archivo:**")
            st.info(f"- **Registros**: {len(df):,}")
            st.info(f"- **Columnas**: {len(df.columns)}")
            st.info(f"- **Per√≠odo**: Detectando...")
            
            # Intentar detectar rango de fechas
            if 'FECHA' in df.columns:
                try:
                    # Primero intentar con el formato espec√≠fico
                    fechas = pd.to_datetime(df['FECHA'], format='%d-%m-%Y %H:%M:%S', errors='coerce')
                    # Si hay muchos valores nulos, intentar con dayfirst=True
                    if fechas.isnull().sum() > len(df) * 0.5:
                        fechas = pd.to_datetime(df['FECHA'], dayfirst=True, errors='coerce')
                    
                    fechas_validas = fechas.dropna()
                    if len(fechas_validas) > 0:
                        fecha_min = fechas_validas.min()
                        fecha_max = fechas_validas.max()
                        st.info(f"- **Rango de fechas**: {fecha_min.date()} a {fecha_max.date()}")
                except:
                    st.warning("‚ö†Ô∏è No se pudo procesar las fechas")
            
            st.rerun()
    
    except Exception as e:
        st.error(f"‚ùå Error procesando archivo: {str(e)}")
        st.info("üí° Verifica que el archivo tenga el formato correcto")

def crear_script_auditoria_temporal(ruta_archivo):
    """Crea un script temporal de auditor√≠a que usa el archivo cargado"""
    
    script_content = f'''
#!/usr/bin/env python3
# Script temporal de auditor√≠a generado autom√°ticamente

import sys
import os
sys.path.append(os.path.dirname(__file__))

from auditoria_datos_llamadas import AuditoriaLlamadasAlodesk

def main():
    # Usar archivo cargado manualmente
    archivo_llamadas = r"{ruta_archivo}"
    output_path = os.path.dirname(__file__)
    
    print("üîç INICIANDO AUDITOR√çA DE DATOS CARGADOS")
    print("=" * 60)
    
    # Crear auditor
    auditor = AuditoriaLlamadasAlodesk(archivo_llamadas)
    
    # Ejecutar auditor√≠a completa
    if auditor.cargar_y_limpiar_datos():
        reporte = auditor.generar_reporte_diagnostico(output_path)
        
        print("\nüéØ RESUMEN EJECUTIVO:")
        print(f"   üìä Total registros: {{len(auditor.df)}}")
        
        if 'recomendaciones' in reporte:
            print(f"   ‚ö†Ô∏è Recomendaciones: {{len(reporte['recomendaciones'])}}")
            
            for rec in reporte['recomendaciones']:
                print(f"   üîß {{rec['tipo']}}: {{rec['problema']}}")
        
        print(f"\nüìÑ Reporte completo disponible")
        
    else:
        print("‚ùå No se pudo completar la auditor√≠a")

if __name__ == "__main__":
    main()
'''
    
    # Guardar script temporal
    script_temp = tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8')
    script_temp.write(script_content)
    script_temp.close()
    
    return script_temp.name

def crear_script_multimodelo_temporal(ruta_archivo, tipo_llamada):
    """Crea un script temporal de multi-modelo que usa el archivo cargado"""
    
    script_content = '''
#!/usr/bin/env python3
# Script temporal de multi-modelo generado automaticamente

import sys
import os
import logging
from datetime import datetime

# Configurar logging para el script temporal
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ceapsi_multimodelo.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('MULTIMODELO')

sys.path.append(os.path.dirname(__file__))

from sistema_multi_modelo import SistemaMultiModeloCEAPSI
import pandas as pd
from pathlib import Path

def main():
    logger.info("=" * 60)
    logger.info("INICIANDO SISTEMA MULTI-MODELO CEAPSI")
    logger.info("=" * 60)
    
    print("INICIANDO SISTEMA MULTI-MODELO CEAPSI")
    print("=" * 60)
    
    # Configurar sistema
    logger.info("Configurando sistema multi-modelo")
    sistema = SistemaMultiModeloCEAPSI()
    
    # Preparar datos desde el archivo cargado
    tipo_llamada = "'''+tipo_llamada+'''"
    archivo_datos = r"'''+ruta_archivo+'''"
    
    logger.info(f"Tipo de llamada: {tipo_llamada}")
    logger.info(f"Archivo de datos: {archivo_datos}")
    
    print("Procesando llamadas " + tipo_llamada + ":")
    print("-" * 40)
    
    # Cargar y procesar datos
    try:
        logger.info("Iniciando carga de datos")
        if not os.path.exists(archivo_datos):
            logger.error(f"Archivo no encontrado: {archivo_datos}")
            print(f"ERROR: Archivo no encontrado: {archivo_datos}")
            return
        
        logger.info("Leyendo archivo CSV")
        df_completo = pd.read_csv(archivo_datos, sep=';', encoding='utf-8')
        logger.info(f"Archivo leido: {len(df_completo)} registros, {len(df_completo.columns)} columnas")
        logger.info(f"Columnas: {list(df_completo.columns)}")
        
        # Procesar fechas
        df_completo['FECHA'] = pd.to_datetime(df_completo['FECHA'], format='%d-%m-%Y %H:%M:%S', errors='coerce')
        df_completo = df_completo.dropna(subset=['FECHA'])
        
        # Filtrar por tipo de llamada
        if 'SENTIDO' in df_completo.columns:
            if tipo_llamada == 'ENTRANTE':
                df_filtrado = df_completo[df_completo['SENTIDO'] == 'in'].copy()
            else:
                df_filtrado = df_completo[df_completo['SENTIDO'] == 'out'].copy()
        else:
            print("Advertencia: No se encontro columna SENTIDO, usando todos los datos")
            df_filtrado = df_completo.copy()
        
        # Filtrar solo dias laborales
        df_filtrado = df_filtrado[df_filtrado['FECHA'].dt.dayofweek < 5]
        
        # Agregar por dia
        df_diario = df_filtrado.groupby(df_filtrado['FECHA'].dt.date).size().reset_index()
        df_diario.columns = ['ds', 'y']
        df_diario['ds'] = pd.to_datetime(df_diario['ds'])
        
        # Agregar regresores basicos
        df_diario['dia_semana'] = df_diario['ds'].dt.dayofweek + 1
        df_diario['es_inicio_mes'] = (df_diario['ds'].dt.day <= 5).astype(int)
        df_diario['semana_mes'] = ((df_diario['ds'].dt.day - 1) // 7) + 1
        
        print("Datos procesados: " + str(len(df_diario)) + " dias de " + tipo_llamada.lower())
        
        if len(df_diario) < 30:
            print("ERROR: Datos insuficientes para entrenamiento (minimo 30 dias)")
            return
        
        # Entrenar todos los modelos
        sistema.entrenar_modelo_arima(df_diario)
        sistema.entrenar_modelo_prophet(df_diario)
        sistema.entrenar_modelos_ml(df_diario)
        
        # Validacion cruzada
        metricas_cv = sistema.validacion_cruzada_temporal(df_diario)
        
        # Calcular pesos ensemble
        sistema.calcular_pesos_ensemble(metricas_cv)
        
        # Generar predicciones
        predicciones = sistema.generar_predicciones_ensemble(df_diario, dias_futuro=28)
        
        if predicciones is not None:
            # Detectar alertas
            alertas = sistema.detectar_alertas_avanzadas(predicciones, df_diario)
            
            # Exportar resultados
            output_path = os.path.dirname(__file__)
            sistema.exportar_resultados_completos(predicciones, alertas, tipo_llamada, output_path)
            
            print("\\nRESUMEN " + tipo_llamada + ":")
            promedio = predicciones['yhat_ensemble'].mean()
            print("   Promedio predicho: " + str(round(promedio, 1)) + " llamadas/dia")
            dia_pico_idx = predicciones['yhat_ensemble'].idxmax()
            dia_pico = predicciones.loc[dia_pico_idx, 'ds'].strftime('%A')
            print("   Dia pico: " + dia_pico)
            print("   Alertas: " + str(len(alertas)) + " detectadas")
            print("\\nSISTEMA MULTI-MODELO COMPLETADO EXITOSAMENTE")
        else:
            print("ERROR: No se pudieron generar predicciones")
            
    except Exception as e:
        print("ERROR: " + str(e))
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
'''
    
    # Guardar script temporal
    script_temp = tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8')
    script_temp.write(script_content)
    script_temp.close()
    
    return script_temp.name

def main():
    """Funci√≥n principal de la aplicaci√≥n Streamlit"""
    
    # Inicializar estado de sesi√≥n
    if 'archivo_datos' not in st.session_state:
        st.session_state.archivo_datos = None
    if 'datos_cargados' not in st.session_state:
        st.session_state.datos_cargados = False
    
    # Sidebar para navegaci√≥n
    st.sidebar.title("üìû CEAPSI - Sistema PCF")
    st.sidebar.markdown("### Precision Call Forecast")
    st.sidebar.markdown("---")
    
    # Secci√≥n de carga de archivos
    mostrar_seccion_carga_archivos()
    
    # Opciones del men√∫
    opciones_menu = {
        "üè† Inicio": "inicio",
        "üìä Dashboard de Validaci√≥n": "dashboard",
        "üîç Auditor√≠a de Datos": "auditoria", 
        "üîÄ Segmentaci√≥n": "segmentacion",
        "ü§ñ Sistema Multi-Modelo": "multimodelo",
        "‚öôÔ∏è Automatizaci√≥n": "automatizacion",
        "üìã Documentaci√≥n": "documentacion"
    }
    
    opcion_seleccionada = st.sidebar.selectbox(
        "Seleccionar M√≥dulo:",
        list(opciones_menu.keys())
    )
    
    modulo = opciones_menu[opcion_seleccionada]
    
    # Estado de la aplicaci√≥n
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Estado del Sistema")
    
    # Verificar datos cargados
    if st.session_state.datos_cargados:
        st.sidebar.success("‚úÖ Datos de llamadas disponibles")
        
        # Mostrar informaci√≥n del archivo cargado
        try:
            df = pd.read_csv(st.session_state.archivo_datos, sep=';')
            st.sidebar.info(f"üìä {len(df):,} registros cargados")
        except:
            st.sidebar.warning("‚ö†Ô∏è Error leyendo datos")
    else:
        st.sidebar.error("‚ùå No hay datos cargados")
        st.sidebar.info("üìÅ Sube un archivo para comenzar")
    
    # Verificar modelos entrenados (solo si hay datos cargados)
    if st.session_state.datos_cargados:
        archivos_modelos = list(Path(__file__).parent.parent.glob("predicciones_multimodelo_*.json"))
        if archivos_modelos:
            st.sidebar.success(f"‚úÖ {len(archivos_modelos)} modelos disponibles")
        else:
            st.sidebar.warning("‚ö†Ô∏è No hay modelos entrenados")
    else:
        st.sidebar.info("ü§ñ Modelos: Pendiente de datos")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"üïê **Actualizado:** {datetime.now().strftime('%H:%M:%S')}")
    
    # Contenido principal seg√∫n la selecci√≥n
    if modulo == "inicio":
        mostrar_inicio()
    elif modulo == "dashboard":
        mostrar_dashboard()
    elif modulo == "auditoria":
        mostrar_auditoria()
    elif modulo == "segmentacion":
        mostrar_segmentacion()
    elif modulo == "multimodelo":
        mostrar_multimodelo()
    elif modulo == "automatizacion":
        mostrar_automatizacion()
    elif modulo == "documentacion":
        mostrar_documentacion()

def mostrar_inicio():
    """P√°gina de inicio del sistema"""
    
    st.title("üè† CEAPSI - Sistema PCF")
    st.markdown("## Precision Call Forecast - Dashboard Principal")
    
    st.markdown("""
    ### üéØ Bienvenido al Sistema de Predicci√≥n de Llamadas
    
    Este sistema utiliza inteligencia artificial avanzada para predecir el volumen de llamadas 
    en su call center. **Sube tu archivo de datos de llamadas** para comenzar el an√°lisis 
    y optimizar la asignaci√≥n de recursos.
    
    üìÅ **¬°Empieza subiendo tu archivo en el sidebar!**
    """)
    
    # Mostrar estado de carga
    if st.session_state.datos_cargados:
        st.success("‚úÖ ¬°Datos cargados! Ya puedes usar todos los m√≥dulos del sistema.")
        
        # Mostrar resumen r√°pido de los datos cargados
        try:
            df = pd.read_csv(st.session_state.archivo_datos, sep=';')
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìä Registros Cargados", f"{len(df):,}")
            with col2:
                if 'FECHA' in df.columns:
                    fechas = pd.to_datetime(df['FECHA'], format='%d-%m-%Y %H:%M:%S', errors='coerce')
                    dias_unicos = fechas.dt.date.nunique()
                    st.metric("üìÖ D√≠as de Datos", f"{dias_unicos}")
                else:
                    st.metric("üìÖ D√≠as de Datos", "N/A")
            with col3:
                if 'SENTIDO' in df.columns:
                    tipos = df['SENTIDO'].value_counts()
                    entrantes = tipos.get('in', 0)
                    salientes = tipos.get('out', 0)
                    st.metric("üìû Tipos", f"E:{entrantes} S:{salientes}")
                else:
                    st.metric("üìû Tipos", "Sin segmentar")
        except:
            st.info("üìä Datos cargados correctamente")
    else:
        st.info("üîÑ Esperando datos... Sube tu archivo CSV o Excel en la secci√≥n 'Cargar Datos' del sidebar.")
        
        # Mostrar instrucci√≥n visual
        st.markdown("""
        üìç **Pasos para comenzar:**
        1. Ve al sidebar ‚Üí "Cargar Datos"
        2. Haz clic en "Seleccionar archivo de llamadas"
        3. Sube tu archivo CSV o Excel
        4. Haz clic en "üöÄ Procesar Archivo"
        5. ¬°Listo! Todos los m√≥dulos estar√°n disponibles
        """)
    
    # M√©tricas principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "üéØ Precisi√≥n Objetivo",
            "MAE < 10",
            "llamadas/d√≠a"
        )
    
    with col2:
        st.metric(
            "üìà Horizonte Predicci√≥n",
            "28 d√≠as",
            "d√≠as laborales"
        )
    
    with col3:
        st.metric(
            "ü§ñ Modelos Activos",
            "5 algoritmos",
            "ensemble h√≠brido"
        )
    
    with col4:
        st.metric(
            "‚ö° Actualizaci√≥n",
            "Autom√°tica",
            "diaria 06:00"
        )
    
    st.markdown("---")
    
    # Caracter√≠sticas principales
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üöÄ Caracter√≠sticas Principales
        
        - **Predicci√≥n Multi-Modelo**: Combina ARIMA, Prophet, Random Forest y Gradient Boosting
        - **Segmentaci√≥n Inteligente**: Separaci√≥n autom√°tica de llamadas entrantes vs salientes
        - **Alertas Avanzadas**: Sistema de detecci√≥n de anomal√≠as y picos de demanda
        - **Validaci√≥n Continua**: Monitoreo autom√°tico de performance de modelos
        - **Visualizaci√≥n Interactiva**: Dashboards en tiempo real con Plotly
        """)
    
    with col2:
        st.markdown("""
        ### üìä M√≥dulos Disponibles
        
        - **üîç Auditor√≠a de Datos**: An√°lisis de calidad y patrones temporales
        - **üîÄ Segmentaci√≥n**: Clasificaci√≥n autom√°tica de tipos de llamada
        - **ü§ñ Sistema Multi-Modelo**: Entrenamiento y predicci√≥n con ensemble
        - **üìä Dashboard de Validaci√≥n**: An√°lisis interactivo de resultados
        - **‚öôÔ∏è Automatizaci√≥n**: Pipeline completo programado
        """)
    
    st.markdown("---")
    
    # Flujo de trabajo recomendado
    st.markdown("### üîÑ Flujo de Trabajo Recomendado")
    
    st.markdown("""
    1. **üîç Auditor√≠a**: Ejecutar an√°lisis de calidad de datos
    2. **üîÄ Segmentaci√≥n**: Clasificar llamadas por tipo
    3. **ü§ñ Multi-Modelo**: Entrenar modelos predictivos
    4. **üìä Dashboard**: Visualizar resultados y validar performance
    5. **‚öôÔ∏è Automatizaci√≥n**: Configurar ejecuci√≥n programada
    """)
    
    # Enlaces r√°pidos
    st.markdown("### üîó Acceso R√°pido")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üöÄ Iniciar Dashboard", use_container_width=True):
            st.session_state['navegacion'] = 'dashboard'
            st.rerun()
    
    with col2:
        if st.button("üîç Ejecutar Auditor√≠a", use_container_width=True):
            st.session_state['navegacion'] = 'auditoria'
            st.rerun()
    
    with col3:
        if st.button("ü§ñ Entrenar Modelos", use_container_width=True):
            st.session_state['navegacion'] = 'multimodelo'
            st.rerun()

def mostrar_dashboard():
    """Ejecuta el dashboard de validaci√≥n"""
    
    if not st.session_state.datos_cargados:
        st.warning("‚ö†Ô∏è No hay datos cargados")
        st.info("üìÅ Por favor, sube un archivo de datos en la secci√≥n 'Cargar Datos' del sidebar")
        
        # Mostrar preview de c√≥mo se ver√≠a el dashboard
        st.markdown("### üîç Vista Previa del Dashboard")
        st.image("https://via.placeholder.com/800x400/f0f2f6/333?text=Dashboard+de+Validaci%C3%B3n", 
                caption="El dashboard mostrar√° gr√°ficas de atenci√≥n, comparaci√≥n de modelos y alertas una vez que subas los datos")
        return
    
    # Crear dashboard personalizado con datos cargados
    dashboard = DashboardValidacionCEAPSI()
    dashboard.base_path = Path(st.session_state.archivo_datos).parent
    dashboard.archivo_datos_manual = st.session_state.archivo_datos
    dashboard.ejecutar_dashboard()

def mostrar_auditoria():
    """M√≥dulo de auditor√≠a de datos"""
    
    st.title("üîç Auditor√≠a de Datos de Llamadas")
    st.markdown("### An√°lisis Profundo de Calidad y Patrones")
    
    if not st.session_state.datos_cargados:
        st.warning("‚ö†Ô∏è No hay datos cargados para auditar")
        st.info("üìÅ Sube un archivo de datos primero")
        return
    
    st.info("üìã Este m√≥dulo analiza la calidad de los datos de llamadas y detecta patrones temporales.")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **El an√°lisis incluye:**
        - ‚úÖ Validaci√≥n de estructura temporal
        - ‚úÖ Detecci√≥n de valores faltantes
        - ‚úÖ An√°lisis de outliers y anomal√≠as
        - ‚úÖ Patrones estacionales
        - ‚úÖ Recomendaciones de mejora
        """)
    
    with col2:
        if st.button("üöÄ Ejecutar Auditor√≠a", use_container_width=True, type="primary"):
            with st.spinner("Ejecutando auditor√≠a de datos..."):
                try:
                    # Crear script temporal que use el archivo cargado
                    script_temp = crear_script_auditoria_temporal(st.session_state.archivo_datos)
                    
                    # Ejecutar script de auditor√≠a
                    result = subprocess.run(
                        [sys.executable, script_temp],
                        cwd=Path(__file__).parent,
                        capture_output=True,
                        text=True,
                        timeout=300,
                        encoding='utf-8',
                        errors='replace'  # Manejar errores de encoding
                    )
                    
                    # Limpiar archivo temporal
                    if os.path.exists(script_temp):
                        os.remove(script_temp)
                    
                    if result.returncode == 0:
                        st.success("‚úÖ Auditor√≠a completada exitosamente")
                        
                        # Mostrar output
                        st.text_area("üìã Resultado de la Auditor√≠a:", result.stdout, height=200)
                        
                        # Buscar archivo de reporte generado
                        reporte_path = Path(__file__).parent.parent / "diagnostico_llamadas_alodesk.json"
                        if reporte_path.exists():
                            st.download_button(
                                "üì• Descargar Reporte Completo",
                                data=reporte_path.read_text(encoding='utf-8'),
                                file_name="diagnostico_llamadas_alodesk.json",
                                mime="application/json"
                            )
                    else:
                        st.error(f"‚ùå Error en auditor√≠a: {result.stderr}")
                        
                except subprocess.TimeoutExpired:
                    st.error("‚è∞ Timeout: La auditor√≠a tom√≥ demasiado tiempo")
                except Exception as e:
                    st.error(f"‚ùå Error ejecutando auditor√≠a: {e}")
    
    # Mostrar resultados previos si existen
    reporte_path = Path(__file__).parent.parent / "diagnostico_llamadas_alodesk.json"
    if reporte_path.exists():
        st.markdown("---")
        st.markdown("### üìä √öltimo Reporte de Auditor√≠a")
        
        try:
            with open(reporte_path, 'r', encoding='utf-8') as f:
                reporte = json.load(f)
            
            # Mostrar m√©tricas principales
            metadata = reporte.get('metadata', {})
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üìä Total Registros", f"{metadata.get('total_registros', 0):,}")
            
            with col2:
                periodo = metadata.get('periodo_datos', {})
                if isinstance(periodo, dict) and 'FECHA' in periodo:
                    rango = periodo['FECHA'].get('rango_fechas', 'N/A')
                    st.metric("üìÖ Per√≠odo", rango)
                else:
                    st.metric("üìÖ Per√≠odo", "N/A")
            
            with col3:
                recomendaciones = reporte.get('recomendaciones', [])
                st.metric("üí° Recomendaciones", len(recomendaciones))
            
            # Mostrar recomendaciones
            if recomendaciones:
                st.markdown("#### üîß Recomendaciones Principales")
                for i, rec in enumerate(recomendaciones[:3], 1):
                    with st.expander(f"{i}. {rec.get('tipo', 'RECOMENDACI√ìN')} - Prioridad: {rec.get('prioridad', 'MEDIA')}"):
                        st.write(f"**Problema:** {rec.get('problema', 'N/A')}")
                        st.write(f"**Soluci√≥n:** {rec.get('solucion', 'N/A')}")
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è No se pudo cargar el reporte: {e}")

def mostrar_segmentacion():
    """M√≥dulo de segmentaci√≥n de llamadas"""
    
    st.title("üîÄ Segmentaci√≥n de Llamadas")
    st.markdown("### Clasificaci√≥n Autom√°tica por Tipo")
    
    if not st.session_state.datos_cargados:
        st.warning("‚ö†Ô∏è No hay datos cargados para segmentar")
        st.info("üìÅ Sube un archivo de datos primero")
        return
    
    st.info("üìã Este m√≥dulo separa autom√°ticamente las llamadas entrantes de las salientes.")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **El proceso incluye:**
        - ‚úÖ Detecci√≥n autom√°tica de direcci√≥n de llamadas
        - ‚úÖ An√°lisis de patrones horarios
        - ‚úÖ Segmentaci√≥n por n√∫meros telef√≥nicos
        - ‚úÖ Generaci√≥n de datasets separados
        - ‚úÖ Validaci√≥n de confianza de clasificaci√≥n
        """)
    
    with col2:
        if st.button("üöÄ Ejecutar Segmentaci√≥n", use_container_width=True, type="primary"):
            with st.spinner("Ejecutando segmentaci√≥n..."):
                try:
                    result = subprocess.run(
                        [sys.executable, "segmentacion_llamadas.py"],
                        cwd=Path(__file__).parent,
                        capture_output=True,
                        text=True,
                        timeout=300
                    )
                    
                    if result.returncode == 0:
                        st.success("‚úÖ Segmentaci√≥n completada exitosamente")
                        st.text_area("üìã Resultado:", result.stdout, height=200)
                    else:
                        st.error(f"‚ùå Error: {result.stderr}")
                        
                except Exception as e:
                    st.error(f"‚ùå Error ejecutando segmentaci√≥n: {e}")

def mostrar_multimodelo():
    """M√≥dulo del sistema multi-modelo"""
    
    st.title("ü§ñ Sistema Multi-Modelo")
    st.markdown("### Entrenamiento y Predicci√≥n con Ensemble")
    
    if not st.session_state.datos_cargados:
        st.warning("‚ö†Ô∏è No hay datos cargados para entrenar modelos")
        st.info("üìÅ Sube un archivo de datos primero")
        return
    
    # Verificar calidad de datos antes de entrenar
    try:
        df = pd.read_csv(st.session_state.archivo_datos, sep=';')
        
        # Verificar columnas necesarias
        if 'FECHA' not in df.columns:
            st.error("‚ùå El archivo debe tener una columna 'FECHA'")
            return
        
        # Procesar fechas para verificar datos v√°lidos
        fechas = pd.to_datetime(df['FECHA'], format='%d-%m-%Y %H:%M:%S', errors='coerce')
        df_validas = df[fechas.notna()]
        
        if len(df_validas) < 100:
            st.error(f"‚ùå Datos insuficientes: {len(df_validas)} registros v√°lidos (m√≠nimo 100)")
            st.info("üí° Necesitas al menos 100 registros con fechas v√°lidas para entrenar modelos")
            return
        
        # Verificar d√≠as √∫nicos
        dias_unicos = fechas.dt.date.nunique()
        if dias_unicos < 30:
            st.error(f"‚ùå Periodo insuficiente: {dias_unicos} d√≠as √∫nicos (m√≠nimo 30 d√≠as)")
            st.info("üí° Necesitas al menos 30 d√≠as de datos para entrenar modelos de series de tiempo")
            return
        
        st.success(f"‚úÖ Datos v√°lidos: {len(df_validas):,} registros en {dias_unicos} d√≠as")
        
    except Exception as e:
        st.error(f"‚ùå Error validando datos: {e}")
        return
    
    # Selector de tipo de llamada
    tipo_llamada = st.selectbox(
        "Seleccionar tipo de llamada:",
        ["ENTRANTE", "SALIENTE"]
    )
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown(f"""
        **Entrenamiento para llamadas {tipo_llamada}:**
        - ü§ñ Modelos: ARIMA, Prophet, Random Forest, Gradient Boosting
        - üìä Ensemble autom√°tico con pesos optimizados
        - üîç Validaci√≥n cruzada temporal
        - üö® Sistema de alertas avanzado
        - üìà Predicciones para 28 d√≠as laborales
        """)
    
    with col2:
        if st.button(f"üöÄ Entrenar {tipo_llamada}", use_container_width=True, type="primary"):
            logger.info(f"Iniciando entrenamiento de modelos para {tipo_llamada}")
            
            with st.spinner(f"Entrenando modelos para llamadas {tipo_llamada.lower()}..."):
                try:
                    logger.info("Creando script temporal de multi-modelo")
                    # Crear script temporal que use el archivo cargado
                    script_temp = crear_script_multimodelo_temporal(st.session_state.archivo_datos, tipo_llamada)
                    logger.info(f"Script temporal creado: {script_temp}")
                    
                    logger.info("Ejecutando subprocess para entrenamiento")
                    result = subprocess.run(
                        [sys.executable, script_temp],
                        cwd=Path(__file__).parent,
                        capture_output=True,
                        text=True,
                        timeout=600,
                        encoding='utf-8',
                        errors='replace'  # Manejar errores de encoding
                    )
                    
                    logger.info(f"Subprocess completado con c√≥digo: {result.returncode}")
                    logger.info(f"STDOUT length: {len(result.stdout) if result.stdout else 0}")
                    logger.info(f"STDERR length: {len(result.stderr) if result.stderr else 0}")
                    
                    if result.stdout:
                        logger.info(f"STDOUT: {result.stdout[:500]}...")  # Primeros 500 caracteres
                    if result.stderr:
                        logger.error(f"STDERR: {result.stderr[:500]}...")  # Primeros 500 caracteres
                    
                    # Limpiar archivo temporal
                    if os.path.exists(script_temp):
                        os.remove(script_temp)
                        logger.info("Archivo temporal limpiado")
                    
                    if result.returncode == 0:
                        st.success(f"‚úÖ Modelos para {tipo_llamada} entrenados exitosamente")
                        st.text_area("üìã Resultado:", result.stdout, height=200)
                        
                        # Buscar archivo de resultados
                        resultados_pattern = f"predicciones_multimodelo_{tipo_llamada.lower()}_*.json"
                        archivos_resultados = list(Path(__file__).parent.parent.glob(resultados_pattern))
                        
                        if archivos_resultados:
                            archivo_mas_reciente = max(archivos_resultados, key=lambda x: x.stat().st_mtime)
                            st.download_button(
                                f"üì• Descargar Resultados {tipo_llamada}",
                                data=archivo_mas_reciente.read_text(encoding='utf-8'),
                                file_name=archivo_mas_reciente.name,
                                mime="application/json"
                            )
                    else:
                        st.error(f"‚ùå Error: {result.stderr}")
                        
                except Exception as e:
                    st.error(f"‚ùå Error ejecutando entrenamiento: {e}")

def mostrar_automatizacion():
    """M√≥dulo de automatizaci√≥n"""
    
    st.title("‚öôÔ∏è Sistema de Automatizaci√≥n")
    st.markdown("### Pipeline Completo Automatizado")
    
    st.info("üìã Sistema de ejecuci√≥n autom√°tica del pipeline completo PCF.")
    
    # Estado de la automatizaci√≥n
    st.markdown("### üìä Estado del Sistema")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üïê Ejecuci√≥n Programada", "06:00 diario")
    
    with col2:
        st.metric("üìß Notificaciones", "Habilitadas")
    
    with col3:
        st.metric("üíæ Backup", "Autom√°tico")
    
    st.markdown("---")
    
    # Controles de automatizaci√≥n
    st.markdown("### üéÆ Controles")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üöÄ Ejecutar Pipeline Completo", use_container_width=True, type="primary"):
            with st.spinner("Ejecutando pipeline completo..."):
                st.info("‚è≥ Esta operaci√≥n puede tomar varios minutos...")
                # Aqu√≠ se ejecutar√≠a el pipeline completo
                st.success("‚úÖ Pipeline ejecutado exitosamente")
    
    with col2:
        if st.button("üîç Verificar Estado", use_container_width=True):
            st.info("‚úÖ Sistema operativo")
            st.info("üìä √öltima ejecuci√≥n: 06:00 AM")
            st.info("üéØ Pr√≥xima ejecuci√≥n: Ma√±ana 06:00 AM")
    
    with col3:
        if st.button("üìß Enviar Reporte", use_container_width=True):
            st.success("üìß Reporte enviado a equipos operativos")

def mostrar_documentacion():
    """Documentaci√≥n del sistema"""
    
    st.title("üìã Documentaci√≥n del Sistema")
    st.markdown("### Gu√≠a Completa del Sistema PCF")
    
    # Tabs para organizar la documentaci√≥n
    tab1, tab2, tab3, tab4 = st.tabs(["üèóÔ∏è Arquitectura", "üìä Modelos", "üîß Configuraci√≥n", "‚ùì FAQ"])
    
    with tab1:
        st.markdown("""
        ### üèóÔ∏è Arquitectura del Sistema
        
        El Sistema PCF (Precision Call Forecast) est√° compuesto por 5 m√≥dulos principales:
        
        #### 1. üîç Auditor√≠a de Datos (`auditoria_datos_llamadas.py`)
        - Validaci√≥n de calidad de datos
        - An√°lisis de patrones temporales
        - Detecci√≥n de outliers y anomal√≠as
        - Generaci√≥n de reportes de diagn√≥stico
        
        #### 2. üîÄ Segmentaci√≥n (`segmentacion_llamadas.py`)
        - Clasificaci√≥n autom√°tica de llamadas entrantes vs salientes
        - An√°lisis de patrones horarios
        - Generaci√≥n de datasets separados
        
        #### 3. ü§ñ Sistema Multi-Modelo (`sistema_multi_modelo.py`)
        - Entrenamiento de m√∫ltiples algoritmos de ML
        - Ensemble autom√°tico con pesos optimizados
        - Generaci√≥n de predicciones
        
        #### 4. üìä Dashboard (`dashboard_comparacion.py`)
        - Visualizaci√≥n interactiva de resultados
        - An√°lisis de performance de modelos
        - Sistema de alertas validado
        
        #### 5. ‚öôÔ∏è Automatizaci√≥n (`automatizacion_completa.py`)
        - Pipeline completo automatizado
        - Sistema de notificaciones
        - Programaci√≥n de tareas
        """)
    
    with tab2:
        st.markdown("""
        ### üìä Modelos de Machine Learning
        
        #### üîÆ Prophet
        - **Prop√≥sito**: Modelado de series de tiempo con estacionalidad
        - **Fortalezas**: Manejo autom√°tico de tendencias y estacionalidad
        - **Par√°metros**: Estacionalidad semanal, sin estacionalidad anual
        
        #### üìà ARIMA
        - **Prop√≥sito**: Modelo cl√°sico de series de tiempo
        - **Fortalezas**: Captura patrones autoregresivos
        - **Optimizaci√≥n**: B√∫squeda autom√°tica de par√°metros (p,d,q)
        
        #### üå≥ Random Forest
        - **Prop√≥sito**: Modelo ensemble basado en √°rboles
        - **Features**: Lags, medias m√≥viles, features temporales
        - **Configuraci√≥n**: 100 estimadores, profundidad m√°xima 10
        
        #### üöÄ Gradient Boosting
        - **Prop√≥sito**: Boosting secuencial de modelos d√©biles
        - **Fortalezas**: Manejo de patrones complejos no lineales
        - **Configuraci√≥n**: 100 estimadores, learning rate 0.1
        
        #### ‚öñÔ∏è Ensemble
        - **M√©todo**: Promedio ponderado basado en performance
        - **Pesos**: Calculados autom√°ticamente usando validaci√≥n cruzada
        - **M√©tricas**: MAE como m√©trica principal de optimizaci√≥n
        """)
    
    with tab3:
        st.markdown("""
        ### üîß Configuraci√≥n del Sistema
        
        #### üìÅ Estructura de Archivos
        ```
        pcf_scripts/
        ‚îú‚îÄ‚îÄ app.py                          # Aplicaci√≥n principal Streamlit
        ‚îú‚îÄ‚îÄ dashboard_comparacion.py        # Dashboard interactivo
        ‚îú‚îÄ‚îÄ auditoria_datos_llamadas.py     # Auditor√≠a de datos
        ‚îú‚îÄ‚îÄ segmentacion_llamadas.py        # Segmentaci√≥n de llamadas
        ‚îú‚îÄ‚îÄ sistema_multi_modelo.py         # Sistema multi-modelo
        ‚îú‚îÄ‚îÄ automatizacion_completa.py      # Automatizaci√≥n
        ‚îú‚îÄ‚îÄ requirements.txt                # Dependencias
        ‚îî‚îÄ‚îÄ README.md                       # Documentaci√≥n
        ```
        
        #### üéØ Objetivos de Performance
        - **MAE Objetivo**: < 10 llamadas/d√≠a
        - **RMSE Objetivo**: < 15 llamadas/d√≠a
        - **MAPE Objetivo**: < 25%
        - **Precisi√≥n Alertas**: > 90%
        
        #### üìä Configuraci√≥n de Modelos
        - **Horizontes de Predicci√≥n**: 1, 3, 7, 14, 28 d√≠as
        - **Ventana de Validaci√≥n**: 30 d√≠as
        - **M√©trica Principal**: MAE (Mean Absolute Error)
        - **Umbral de Precisi√≥n**: 15.0 MAE m√°ximo
        """)
    
    with tab4:
        st.markdown("""
        ### ‚ùì Preguntas Frecuentes
        
        #### üîç ¬øC√≥mo interpretar las m√©tricas MAE y RMSE?
        - **MAE (Mean Absolute Error)**: Error promedio en n√∫mero de llamadas. Un MAE de 5 significa que las predicciones se desv√≠an en promedio 5 llamadas del valor real.
        - **RMSE (Root Mean Square Error)**: Penaliza m√°s los errores grandes. √ötil para detectar si hay d√≠as con errores muy altos.
        
        #### üìä ¬øQu√© significa el peso en el ensemble?
        Los pesos indican la contribuci√≥n de cada modelo a la predicci√≥n final. Un peso alto significa que el modelo tiene mejor performance y contribuye m√°s al resultado.
        
        #### üö® ¬øC√≥mo funcionan las alertas?
        Las alertas se generan comparando las predicciones con umbrales hist√≥ricos:
        - **Cr√≠tica**: >2.5œÉ por encima de la media hist√≥rica
        - **Alta**: >1.5œÉ por encima de la media hist√≥rica
        - **Media**: Patrones inusuales detectados
        
        #### üîÑ ¬øCon qu√© frecuencia se actualizan los modelos?
        - **Predicciones**: Diariamente a las 06:00 AM
        - **Reentrenamiento**: Semanalmente los domingos
        - **Validaci√≥n**: Continua con cada ejecuci√≥n
        
        #### üìû ¬øC√≥mo se segmentan las llamadas?
        La segmentaci√≥n se basa en:
        1. Columna SENTIDO ('in' para entrantes, 'out' para salientes)
        2. Patrones horarios (llamadas comerciales vs seguimiento)
        3. An√°lisis de n√∫meros telef√≥nicos
        
        #### üí° ¬øQu√© hacer si la precisi√≥n es baja?
        1. Verificar calidad de datos con auditor√≠a
        2. Revisar si hay cambios en patrones de negocio
        3. Considerar reentrenamiento con m√°s datos
        4. Ajustar umbrales de alertas
        """)

if __name__ == "__main__":
    main()
